apiVersion: tekton.dev/v1beta1
kind: Task
metadata:
  name: create-cluster-capi-hybrid
  namespace: test-workloads
spec:
  volumes:
  - name: endpoints-config
    secret:
      secretName: standup-endpoints-config
  - name: kubeconfig
    secret:
      secretName: standup-kubeconfig
  workspaces:
  - name: cluster
    description: Cluster information is stored here.
  params:
  - name: release-id
    type: string
    description: Release ID to use when creating the cluster.
  results:
  - name: cluster-id
    description: The ID of the created cluster.
  steps:
  - name: create-cluster
    image: quay.io/giantswarm/kubectl-gs:2.4.0
    volumeMounts:
      - name: endpoints-config
        mountPath: /etc/endpoints-config
      - name: kubeconfig
        mountPath: /etc/kubeconfig
    script: |
      #! /bin/sh

      set -e
      set -x

      export KUBECONFIG=/etc/kubeconfig/$(cat $(workspaces.cluster.path)/installation)

      # Generate template for control plane.
      kubectl-gs template cluster \
        --kubeconfig /etc/kubeconfig/$(cat $(workspaces.cluster.path)/installation) \
        --provider $(cat $(workspaces.cluster.path)/installation) \
        --release $(params.release-id) \
        --organization giantswarm \
        --description "e2e test" \
        --output /tmp/cluster.yaml

      # Extract cluster name from template.
      cluster_id=$(cat /tmp/cluster.yaml | grep cluster.x-k8s.io/cluster-name | head -n1 | cut -d" " -f6)

      echo -n "${cluster_id}" >$(workspaces.cluster.path)/cluster-id
      echo -n "${cluster_id}" > $(results.cluster-id.path)

      # AZ is mandatory on AWS, so we need an if here.
      # Also, we run tests for AWS on gaia, in eu-central-1
      AZS=""
      if [ $(cat $(workspaces.cluster.path)/installation) == "aws" ]
      then
        AZS="--availability-zones eu-central-1a"
      fi

      kubectl-gs template nodepool \
        --provider $(cat $(workspaces.cluster.path)/installation) \
        --release $(params.release-id) \
        --organization giantswarm \
        --cluster-name "${cluster_id}" \
        --description "np1" \
        --nodes-min 3 \
        --nodes-max 10 \
        $AZS \
        --output /tmp/nodepool.yaml

      set +e
      # Try applying the cluster YAML 5 times to support transient failures in the apply process.
      ok="false"
      for i in $(seq 1 5); do
        cat /tmp/cluster.yaml | kubectl apply -f -
        success=$?
        if [ "$success" -eq "0" ]; then
          ok="true"
          break
        fi

        sleep 15
      done

      # This function splits a multi-document yaml file into single yaml manifests
      # and retries applying each manifest up to 5 times in case of failure.
      retry_single() {
        x="$(cat $1)"
        while [[ -n "$x" ]]
        do
          ary+=("${x%%---*}")
          if [[ "$x" =~ --- ]]
          then
            x="${x#*---}"
          else
            x=''
          fi
        done
        for yml in "${ary[@]}"
        do
          ok="false"
          for i in $(seq 1 5); do
            echo "$yml" | kubectl apply -f -
            success=$?
            if [ "$success" -eq "0" ]; then
              ok="true"
              break
            fi
          done

          if [ "$ok" != "true" ]
          then
            echo "Failed to apply $1"
            exit 1
          fi
        done
      }

      retry_single /tmp/cluster.yaml
      retry_single /tmp/nodepool.yaml

  - name: legacy-get-kubeconfig
    image: quay.io/giantswarm/kubectl:1.22.3
    volumeMounts:
      - name: endpoints-config
        mountPath: /etc/endpoints-config
      - name: kubeconfig
        mountPath: /etc/kubeconfig
    script: |
      #!/bin/sh

      if echo $(params.release-id) | grep "v20.0.0"
      then
        echo "Release $(params.release-id) is a CAPI release"
        exit 0
      fi

      export KUBECONFIG=/etc/kubeconfig/$(cat $(workspaces.cluster.path)/installation)
      for i in $(seq 1 20); do
        cluster_id=$(cat $(workspaces.cluster.path)/cluster-id)
        json="$(kubectl -n ${cluster_id} get secret ${cluster_id}-kubeconfig -o json)"
        success=$?
        if [ "$success" -eq "0" ]; then
          echo "${json}"| jq -r .data.kubeConfig | base64 -d >$(workspaces.cluster.path)/kubeconfig
          break
        fi
        sleep 5
      done
      exit $success

  - name: capi-get-kubeconfig
    image: quay.io/giantswarm/clusterctl:0.4.2
    volumeMounts:
      - name: endpoints-config
        mountPath: /etc/endpoints-config
      - name: kubeconfig
        mountPath: /etc/kubeconfig
    script: |
      #! /bin/sh

      if [[ "$(params.release-id)" != "v20.0.0"* ]]
      then
        echo "Release $(params.release-id) is not a CAPI release"
        exit 0
      fi

      export KUBECONFIG=/etc/kubeconfig/$(cat $(workspaces.cluster.path)/installation)
      for i in $(seq 1 20); do
        clusterctl -n org-giantswarm get kubeconfig $(cat $(workspaces.cluster.path)/cluster-id) >$(workspaces.cluster.path)/kubeconfig
        success=$?
        if [ "$success" -eq "0" ]; then
          break
        fi
        sleep 5
      done
      exit $success
